-------------------------------
Model: XGBClassifier
Best Score (make_scorer(roc_auc_score)): 0.8363485046347008
Best Params: {'model__max_depth': 3, 'model__min_child_weight': 5, 'preparation__cap_gain_loss_pipeline__custom_transform__base': 2.718281828459045, 'preparation__num_pipeline__combine_agehours__combine': False}
Time: -12768.1s


NOTE BUT THIS IS A LOWER SCORE
-------------------------------
Model: XGBClassifier
Best Score (make_scorer(roc_auc_score)): 0.8282759562404396
Best Params: {'model__max_depth': 4, 'model__min_child_weight': 3}
Time: -1529.9s




(0.8342108218915141, {'model__colsample_bytree': 0.6, 'model__subsample': 0.9})

============================================================================================================
         'model__subsample':[0.8, 0.85, 0.9, 0.95, 1],
         'model__colsample_bytree': [0.4, 0.5, 0.6, 0.65, 0.7],
(0.8387775058479304, {'model__colsample_bytree': 0.4, 'model__subsample': 1})

============================================================================================================
         'model__subsample':[0.9, 1],
         'model__colsample_bytree': [0.3, 0.4, 0.5],
         'model__n_estimators': [500, 1000, 1500],


0.8432343905769959,
 {'model__colsample_bytree': 0.4,
  'model__n_estimators': 500,
  'model__subsample': 1})

============================================================================================================
[{'model__subsample': [0.9, 1],
  'model__colsample_bytree': [0.3, 0.4, 0.5],
  'model__n_estimators': [50, 100, 250, 500]}]

(0.8446717073631916,
 {'model__colsample_bytree': 0.3,
  'model__n_estimators': 250,
  'model__subsample': 0.9})
  ============================================================================================================
  [{'model__subsample': [0.85, 0.9, 0.95],
  'model__colsample_bytree': [0.25, 0.3, 0.35],
  'model__n_estimators': [150, 250, 350]}]

  (0.8442568879097755,
 {'model__colsample_bytree': 0.25,
  'model__n_estimators': 150,
  'model__subsample': 0.95})
  ============================================================================================================
  [{'model__subsample': [0.9, 0.95, 1],
  'model__colsample_bytree': [0.15, 0.2, 0.25, 0.3],
  'model__n_estimators': [50, 100, 150, 200]}]

  (0.8449367698265818,
 {'model__colsample_bytree': 0.15,
  'model__n_estimators': 200,
  'model__subsample': 0.95})


  ============================
[{'model__subsample': [0.9, 0.95, 1],
  'model__colsample_bytree': [0.1, 0.15, 0.2],
  'model__n_estimators': [150, 200, 250]}]

  (0.8448732897856133,
 {'model__colsample_bytree': 0.15,
  'model__n_estimators': 250,
  'model__subsample': 0.9})

  =============================
  [{'model__subsample': [0.85, 0.9, 0.95],
  'model__colsample_bytree': [0.1, 0.15, 0.2],
  'model__n_estimators': [200, 250, 300]}]

  (0.8454695731763837,
 {'model__colsample_bytree': 0.15,
  'model__n_estimators': 300,
  'model__subsample': 0.95})


  ============================
[{'model__subsample': [0.9, 0.95, 1.0],
  'model__colsample_bytree': [0.1, 0.15, 0.2],
  'model__n_estimators': [250, 300, 350]}]

  (0.8448745317338672,
 {'model__colsample_bytree': 0.1,
  'model__n_estimators': 250,
  'model__subsample': 0.95})

  =============================
[{'model__reg_alpha': [0, 0.001, 0.005, 0.01, 0.05]}]

(0.8446869378232749, {'model__reg_alpha': 0.005}), 

NOTE: worse, than previous , consider tuning [0, 0.001, 0.005, 0.01 in final tune

============================

[{'model__learning_rate': [0.005, 0.01, 0.05, 0.1, 0.3],
  'model__n_estimators': [300, 500, 1000, 2000]}]

0.8451274018474221,
 {'model__learning_rate': 0.05, 'model__n_estimators': 1000})


 =============================
[{'model__learning_rate': [0.01, 0.05, 0.1],
  'model__n_estimators': [750, 1000, 1250, 1500]}]

 (0.8454444568126084,
 {'model__learning_rate': 0.05, 'model__n_estimators': 1500})
================================

[{'model__learning_rate': [0.01, 0.05, 0.1],
  'model__n_estimators': [1500, 2000, 3000]}]

  (0.844744426019363,
 {'model__learning_rate': 0.05, 'model__n_estimators': 1500})



 ==========================================
 [{'model__scale_pos_weight': [1, 3.034796573875803, 5]}]

 (0.8461574727013513, {'model__scale_pos_weight': 3.034796573875803})

=============================================

 (0.8458019089367627,
 {'preparation__cap_gain_loss_pipeline__custom_cap_gain_minus_loss__combine': True})


======================================================
 {'n_estimators': [1250, 1500, 1750],
 'max_depth': [3, 4, 5],
 'min_child_weight': [2, 3, 4],
 'subsample': [0.9, 0.95, 1]}

{'n_estimators': 1750, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 1.0}
{'BINARY_AUC': 0.8457153054881816,
 'AUC_ROC': 0.9297213921879113,
 'F_BETA': 0.6565762775126679,
 'sensitivity': 0.8673808546152647,
 'positive_predictive_value': 0.6189823694407532}

- Try > 1750 for n_estimators, <2 for min_child_weight


==========================================================

tuner.results.best_hyper_params
tuner.results.best_hyper_params
{'subsample': 1.0, 'colsample_bytree': 0.5}

params_dict
params_dict
{'subsample': [0.97, 0.98, 0.99, 1.0], 'colsample_bytree': [0.5, 0.6, 0.7]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.9289872405473832,
 'F_BETA': 0.6532018384754944,
 'sensitivity': 0.8671098479100782,
 'positive_predictive_value': 0.6152707986944443}

 ============================================================
 {'subsample': 1.0, 'colsample_bytree': 0.45}

params_dict
params_dict
{'subsample': [0.98, 0.99, 1.0], 'colsample_bytree': [0.45, 0.5, 0.55]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.9290879233436532,
 'F_BETA': 0.653613097161746,
 'sensitivity': 0.8672407963834001,
 'positive_predictive_value': 0.6157108246093156}
==============================================================================
 {'AUC_ROC': 0.9291771411334655,
 'F_BETA': 0.653979168985783,
 'sensitivity': 0.8675399345384709,
 'positive_predictive_value': 0.6160802222273272}
==============================================================================
 {'reg_alpha': 0, 'reg_lambda': 2}

params_dict
{'reg_alpha': [0, 1, 2], 'reg_lambda': [1, 2, 3]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.9294366782004522,
 'F_BETA': 0.654825151646448,
 'sensitivity': 0.8676391180353942,
 'positive_predictive_value': 0.6170042974065827}
==============================================================================
 {'reg_alpha': 0.0, 'reg_lambda': 2.0}

params_dict
{'reg_alpha': [0, 0.01, 0.25, 0.05], 'reg_lambda': [1.5, 2, 2.5]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.9294366782004522,
 'F_BETA': 0.654825151646448,
 'sensitivity': 0.8676391180353942,
 'positive_predictive_value': 0.6170042974065827}
==============================================================================
 {'learning_rate': 0.05, 'n_estimators': 3000}

params_dict
{'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
 'n_estimators': [1000, 2000, 3000, 4000]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.9295263076658143,
 'F_BETA': 0.6558908677615406,
 'sensitivity': 0.8667017272928185,
 'positive_predictive_value': 0.6183076557668854}

==============================================================================
{'learning_rate': 0.05, 'n_estimators': 2500}

params_dict
{'learning_rate': [0.04, 0.05, 0.06, 0.07], 'n_estimators': [2500, 3000, 3500]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.9295549505696222,
 'F_BETA': 0.6553446148230152,
 'sensitivity': 0.8670933113857514,
 'positive_predictive_value': 0.6176509787117217}
 ==============================================================================
 {'learning_rate': 0.045, 'n_estimators': 3000}

params_dict
{'learning_rate': [0.045, 0.05, 0.055],
 'n_estimators': [2500, 2750, 3000, 3250]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.929568975930517,
 'F_BETA': 0.6551097944387684,
 'sensitivity': 0.8666750853195937,
 'positive_predictive_value': 0.6174425178208235}
================================================================================
{'learning_rate': 0.045, 'n_estimators': 3000}

params_dict
{'learning_rate': [0.04, 0.045, 0.05, 0.055],
 'n_estimators': [2500, 2750, 3000, 3250]}

tuner.results.best_model_resampler_object.score_means
{'AUC_ROC': 0.929568975930517,
 'F_BETA': 0.6551097944387684,
 'sensitivity': 0.8666750853195937,
 'positive_predictive_value': 0.6174425178208235}

 chose 0.05; 2500